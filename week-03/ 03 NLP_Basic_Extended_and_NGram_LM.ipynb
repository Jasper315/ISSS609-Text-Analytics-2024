{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Exercise #3.1: Regular Expressions\n",
    "\n",
    "## Introduction\n",
    "In this hands-on exercise, you are tasked with enhancing a Python program that currently uses regular expressions to identify integers and real numbers. Your objective is to expand its capabilities to recognize a broader range of string patterns, including prices, email addresses, and Python identifiers.\n",
    "\n",
    "## Program Behavior\n",
    "By default, the program reads lines from standard input, attempts to match each line against a list of regular expressions, and outputs the name of the pattern that matches or \"unknown\" if there is no match.\n",
    "\n",
    "## Task Description\n",
    "In the `main()` function of the program, there is the following list of tuples. Each tuple contains a regular expression and the name of the pattern it recognizes:\n",
    "\n",
    "```python\n",
    "patterns = [\n",
    "    (r'^\\d+$', 'integer'),\n",
    "    (r'^\\d+\\.\\d+$', 'real number'),\n",
    "]\n",
    "```\n",
    "\n",
    "Your task is to add additional entries to this list to match the following types of strings:\n",
    "\n",
    "### Price\n",
    "Matches a price in SGD dollars. The number of cents is optional, but there must be two digits if the cents are shown. There may optionally be a comma separating thousands, millions, etc.\n",
    "\n",
    "**Valid prices**:\n",
    "- `$1`\n",
    "- `$20`\n",
    "- `$1.99`\n",
    "- `$10.00`\n",
    "- `$1500.50`\n",
    "- `$2,000.99`\n",
    "- `$1,234,567.89`\n",
    "\n",
    "**Invalid prices**:\n",
    "- `$1.9` (cents must have two digits if present)\n",
    "- `$10,23.4` (improper comma placement)\n",
    "\n",
    "### Email Address\n",
    "Capturing all the rules for what makes a valid email address is complex, so we will use a simplified definition of a valid email address. This definition generally works just fine for extracting email addresses from documents.\n",
    "\n",
    "The first part of the email address is the username portion, and it must not contain whitespace or the @ symbol. The username portion is followed by the @ symbol. After the @ symbol is the domain, which does not contain any whitespace or the @ symbol. The domain contains two or more non-empty components which are separated by periods. The final component must consist of only letters from the English alphabet.\n",
    "\n",
    "**Valid email addresses**:\n",
    "- `nsommer@smu.edu`\n",
    "- `n.sommer@phdcs.smu.edu`\n",
    "- `yippee_skippy@yee-haw.edu`\n",
    "- `fun-times@Taylor.hall.smu.edu`\n",
    "\n",
    "**Invalid email addresses**:\n",
    "- `n@sommer@smu.edu` (multiple '@' symbols)\n",
    "- `n sommer@smu.edu` (spaces not allowed)\n",
    "- `nsommer@smu..edu` (consecutive periods not allowed)\n",
    "- `nsommer@smu.edu-org` (hyphen in last domain extension)\n",
    "\n",
    "### Python Identifiers\n",
    "A python identifier is a name for a function, variable, etc. in a python program. A python identifier must contain only letters, digits, and underscores and the first character must be a letter or an underscore.\n",
    "\n",
    "**Valid Python identifiers**:\n",
    "- `x`\n",
    "- `x1y2`\n",
    "- `_hello`\n",
    "- `funName`\n",
    "- `FunName`\n",
    "\n",
    "**Invalid Python identifiers**:\n",
    "- `1x` (cannot start with a digit)\n",
    "- `bad name` (spaces are not allowed)\n",
    "- `!name` (special characters other than underscore are not allowed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sys\n",
    "\n",
    "def main():\n",
    "    patterns = [\n",
    "        (re.compile(r'^\\d+$'), 'integer'),\n",
    "        (re.compile(r'^\\d+\\.\\d+$'), 'real number'),\n",
    "\n",
    "        raise NotImplementedError(\"You need to implement this.\"),\n",
    "        \"\"\"you need to implement the following patterns:\n",
    "            - a pattern verifying if the input is a valid price\n",
    "            - a pattern verifying if the input is a email address\n",
    "            - a pattern verifying if the input is a python identifier\n",
    "        \"\"\"\n",
    "    ]\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Reading from standard input. Enter lines to match, or press 'quit' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            \n",
    "            input_line = input(\"Enter a string: \")\n",
    "            if input_line.lower() == \"quit\" or input_line.lower() == \"\":\n",
    "                print(\"Exiting program.\")\n",
    "                break\n",
    "\n",
    "            matched = False\n",
    "            for pattern, name in patterns:\n",
    "                if pattern.match(input_line):\n",
    "                    print(f\"{input_line}: {name}\")\n",
    "                    matched = True\n",
    "                    break\n",
    "            if not matched:\n",
    "                print(f\"{input_line}: unknown\")\n",
    "\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Exiting program.\")\n",
    "            break\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise #3.2: Building N-gram Language Models with NLTK\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this exercise, you are tasked with implementing N-gram language models using the NLTK library and the Reuters corpus. This exercise will help you understand how to process text, build N-gram models, and predict the next word in a sequence.\n",
    "\n",
    "\n",
    "## Task Description\n",
    "\n",
    "Below is the basic code structure for building N-gram language models with NLTK. Your tasks are to complete the following implementations:\n",
    "\n",
    "### Task 1: Create N-Grams\n",
    "- Extract Ngrams from the list of words using NLTK. This involves taking consecutive words from the corpus to form a set.\n",
    "\n",
    "### Task 2: Build N-Grams Model\n",
    "\n",
    "- Count Frequency: Develop a frequency model for Ngrams. This step involves counting the occurrences of each Ngrams within the corpus.\n",
    "- Calculate Probabilities: Convert these frequency counts into probabilities. Normalize the counts of Ngrams that end with each possible subsequent word by the total counts of Ngrams that start with the previous words.\n",
    "\n",
    "### Task 3: Implement Prediction Function\n",
    "- Implement a function predict_next_word() that predicts the next word based on the input words using your N-Grams model.\n",
    "\n",
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package reuters to\n",
      "[nltk_data]     /home/jingguiliang/nltk_data...\n",
      "[nltk_data]   Package reuters is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/jingguiliang/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import nltk\n",
    "from nltk import bigrams, trigrams\n",
    "from nltk.corpus import reuters\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('reuters')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input words are: ['the', 'news', 'is']\n",
      "Predicted Next Word using Bigram Model: expected\n",
      "The input words are: ['the', 'stock', 'of']\n",
      "Predicted Next Word using Bigram Model: the\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text\n",
    "words = nltk.word_tokenize(' '.join(reuters.words()))\n",
    "\n",
    "\n",
    "def UniGramModel(words):\n",
    "\n",
    "    \"\"\"Task 1: Implement unigram using NLTK\"\"\"\n",
    "    uni_grams = words\n",
    "\n",
    "    \"\"\"Task 2: Build a unigram model\"\"\"\n",
    "    model = defaultdict(lambda: 0)\n",
    "\n",
    "    \"\"\"Task 3: Count frequency of each word and transform the counts into probabilities\"\"\"\n",
    "    for word in uni_grams:\n",
    "        model[word] += 1\n",
    "\n",
    "    total_count = float(sum(model.values()))\n",
    "    for word in model:\n",
    "        model[word] /= total_count\n",
    "\n",
    "    \"\"\"Task 4: Predict the next word using the unigram model\"\"\"\n",
    "    def predict_next_word(model=model):\n",
    "        \"\"\"\n",
    "        Predicts the next word using the trained unigram model.\n",
    "        Returns:\n",
    "        str: The predicted next word.\n",
    "        \"\"\"\n",
    "        return random.choices(list(model.keys()), list(model.values()))[0]\n",
    "    \n",
    "    input_word = input(\"Enter the previous word: \")\n",
    "    print(\"The input words are:\", input_word)\n",
    "    \n",
    "    input_word = input_word.strip().lower().split()\n",
    "    print(\"Predicted Next Word using Unigram Model:\", predict_next_word())\n",
    "\n",
    "\n",
    "def BiGramModel(words):\n",
    "    \n",
    "    \n",
    "    raise NotImplementedError(\"You need to implement Task 1~4.\")\n",
    "    \"\"\"Task 1: Implement trigram using NLTK\"\"\"\n",
    "    \n",
    "    \"\"\"Task 2: Build a bigram model\"\"\"\n",
    "    \n",
    "    \"\"\"Task 3: Count frequency of co-occurrence and transform the counts into probabilities\"\"\"\n",
    "\n",
    "    \"\"\"Task 4: Predict the next word using the bigram model\"\"\"\n",
    "\n",
    "    def predict_next_word(w1, model):\n",
    "        \"\"\"\n",
    "        Predicts the next word based on the previous word using the trained bigram model.\n",
    "        Args:\n",
    "        w1 (str): The first word.\n",
    "\n",
    "        Returns:\n",
    "        str: The predicted next word.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You need to implement this.\")\n",
    "    \n",
    "    input_word = input(\"Enter the previous word: \")\n",
    "    print(\"The input words are:\", input_word)\n",
    "    \n",
    "    input_word = input_word.strip().lower().split()\n",
    "    print(\"Predicted Next Word using Bigram Model:\", predict_next_word(input_word[-1])) \n",
    "\n",
    "\n",
    "\n",
    "def TriGramModel(words):\n",
    "\n",
    "    raise NotImplementedError(\"You need to implement Task 1~4.\")\n",
    "    \"\"\"Task 1: Implement trigram using NLTK\"\"\"\n",
    "\n",
    "    \"\"\"Task 2: Build a trigram model\"\"\"\n",
    "\n",
    "    \"\"\"Task 3: Count frequency of co-occurrence and transform the counts into probabilities\"\"\"\n",
    "\n",
    "    \"\"\"Task 4: Predict the next word using the trigam model\"\"\"\n",
    "    def predict_next_word(w1, w2, model=model):\n",
    "        \"\"\"\n",
    "        Predicts the next word based on the previous two words using the trained trigram model.\n",
    "        Args:\n",
    "        w1 (str): The first word.\n",
    "        w2 (str): The second word.\n",
    "\n",
    "        Returns:\n",
    "        str: The predicted next word.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"You need to implement this.\")\n",
    "\n",
    "    \n",
    "    input_word = input(\"Enter the previous word: \")\n",
    "    print(\"The input words are:\", input_word)\n",
    "    \n",
    "    input_word = input_word.strip().lower().split()\n",
    "    print(\"Predicted Next Word using Trigram Model:\", predict_next_word(input_word[-2], input_word[-1]))\n",
    "\n",
    "\n",
    "\n",
    "# Test the unigram model\n",
    "UniGramModel(words)\n",
    "\n",
    "# Test the bigram model\n",
    "BiGramModel(words)\n",
    "\n",
    "# Test the trigram model\n",
    "TriGramModel(words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isss609",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
